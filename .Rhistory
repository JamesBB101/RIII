sample_mean
sde
c(qnorm(0.025,sample_mean,sde),qnorm(0.975,sample_mean,sde))
rnorm(n=1000,mean = 3,sd = 2) #在R裡面常態分配參數mean平均數  sd標準差
hist(rnorm(100000,mean = 3,sd = 2))
hist(rnorm(100000,mean = 3,sd = 2))
?qnorm
?pbinom
dbinom(x = 0,size = 3, prob= 0.5)
dbinom(x = 1,size = 3, prob= 0.5)
dbinom(x = 2,size = 3, prob= 0.5)
sde
?qt
qnorm(0.025)
qt(p=0.025,df=n-1)
curve(dnorm(x), -5, 5, col="black")
curve(dnorm(x,mean=0,sd=1),-3,3)
curve(pnorm(x,mean=0,sd=1),-3,3)
pnorm(1) - pnorm(0)
?curve
?dnorm
dnorm(x)
?dnorm
?curve
curve(dnorm(x), -5, 5, col="black")
dnorm(x)
curve(dt(x, df=2), -5, 5, col="green", add=T)
CLT = function(x) {
op<-par(mfrow=c(2,2)) # 設為 2*2 的四格繪圖版
hist(x, breaks=50)     # 繪製 x 序列的直方圖 (histogram)。
m2 <- matrix(x, nrow=2 )  # 將 x 序列分為 2*k 兩個一組的矩陣 m2。
xbar2 <- apply(m2, 2, mean)   # 取每兩個一組的平均值 (x1+x2)/2 放入 xbar2 中。   col平均
hist(xbar2, breaks=50)     # 繪製 xbar2 序列的直方圖 (histogram)。
m10 <- matrix(x, nrow=10 )   # 將 x 序列分為 10*k 兩個一組的矩陣 m10。
xbar10 <- apply(m10, 2, mean) # 取每10個一組的平均值 (x1+..+x10)/10 放入 xbar10 中。
hist(xbar10, breaks=50)    # 繪製 xbar10 序列的直方圖 (histogram)。
m20 <- matrix(x, nrow=20 )   # 將 x 序列分為 25*k 兩個一組的矩陣 m25。
xbar20 <- apply(m20, 2, mean) # 取每20個一組的平均值 (x1+..+x20)/20 放入 xbar20 中。
hist(xbar20, breaks=50)    # 繪製 xbar20 序列的直方圖 (histogram)。
}
CLT(rbinom(n=100000, size = 20, prob = 0.1)) # 用參數為 n=20, p=0.5 的二項分布驗證中央極限定理。
CLT(runif(n=100000,min = 0,max = 1)) # 用參數為 a=0, b=1 的均等分布驗證中央極限定理。
CLT(rpois(n=100000, lambda = 4)) # 用參數為 lambda=4 的布瓦松分布驗證中央極限定理。
CLT(rgeom(n=100000, prob = 0.7)) # 用參數為 p=0.5 的幾何分布驗證中央極限定理。
CLT(rbinom(n=100000, size = 20, prob = 0.1)) # 用參數為 n=20, p=0.5 的二項分布驗證中央極限定理。
m2
m2 <- matrix(x, nrow=2 )
churn
data(churn)
library(caret)
data(churn)
control=trainControl(method="repeatedcv", number=10, repeats=3)
model =train(churn~., data=trainset, method="rpart", trControl=control)
install.packages("caret")
install.packages("caret")
library(caret)
install.packages("caret")
control=trainControl(method="repeatedcv", number=10, repeats=3)
install.packages("caret")
install.packages("caret")
install.packages("caret")
model =train(churn~., data=trainset, method="rpart", trControl=control)
model =train(churn~., data=trainset, method="rpart", trControl=control)
model
predictions = predict(model, testset)
x = c(160,170,180)
y = c(64, 68, 72)
#計算共變異數
cov_xy = sum((x - mean(x)) * (y - mean(y))) / 2
cov_xy
cov(x,y)
#計算相關係數
cor_xy = cov(x,y) / (sd(x) * sd(y))
cor_xy
cor(x,y)
plot(x,y)
#example1:
data(mtcars)
mtcars
cov(mtcars)
cor(mtcars)
cov(mtcars[1:3])
#example2:
gdp = read.csv("data/gdp.csv",header=TRUE)
gdp = gdp[1:15,]
gdp$GDP = as.numeric(sub(",", "", gdp$GDP))
gdp$Export = as.numeric(sub(",", "", gdp$Export))
cor(gdp$Export, gdp$GDP)
install.packages("C50")
library(C50)
data(churn)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
#選擇建模變數
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')    #篩選資料
churnTrain=churnTrain[,variable.list]        #充新寫入欄位
str(churnTrain)
..
model =train(churn~., data=trainset, method="rpart", trControl=control)
importance = varImp(model, scale=FALSE)
library('caret')
library('caret')
library(caret)
library(C50)
library(caret)
data(churn)
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
set.seed(2)
#把資料分成training data 和 testing data
ind<-sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
churn.rp<-rpart(churn ~., data=trainset)
library(caret)
library(rminer)
model=fit(churn~.,trainset,model="rpart")
VariableImportance=Importance(model,trainset)
L=list(runs=1,sen=t(VariableImportance$imp),sresponses=VariableImportance$sresponses)
mgraph(L,graph="IMP",leg=names(trainset),col="gray",Grid=10)
churn.rp
predictions <-predict(churn.rp, testset)
install.packages("rminer")
library(rminer)
model=fit(churn~.,trainset,model="rpart")
VariableImportance=Importance(model,trainset)
L=list(runs=1,sen=t(VariableImportance$imp),sresponses=VariableImportance$sresponses)
mgraph(L,
install.packages("rminer")
predictions <-predict(churn.rp, testset)
predictions
install.packages("ROCR")
library(ROCR)
predictions <-predict(churn.rp, testset, type="prob")
library(caret)
library(e1071)
confusionMatrix(table(predictions, testset$churn))
Sys.setlocale("LC_ALL","C")
library(caret)
library('caret')
install.packages("caret")
install.packages("caret")
library(caret)
library('caret')
predictions <-predict(churn.rp, testset)
library
predictions <-predict(churn.rp, testset)
data(churn)
predictions <-predict(churn.rp, testset)
install.packages("rminer")
library(rminer)
model=fit(churn~.,trainset,model="rpart")
VariableImportance=Importance(model,trainset)
L=list(runs=1,sen=t(VariableImportance$imp),sresponses=VariableImportance$sresponses)
mgraph
predictions <-predict(churn.rp, testset)
install.packages("ROCR")
library(ROCR)
predictions <-predict(churn.rp, testset, type="prob")
churn.rp<-rpart(churn ~ ., data=trainset)     #churn資料的所有類別做分類
install.packages('rpart')
install.packages("rpart")
install.packages("rpart")
library('rpart')
library('rpart')
install.packages('rpart')
install.packages("rpart")
library('rpart')
churn.rp<-rpart(churn ~ ., data=trainset)     #churn資料的所有類別做分類
churn.rp
summary(churn.rp)
predictions <-predict(churn.rp, testset, type="prob")
head(predictions)
pred.to.roc<-predictions[, 1]
head(pred.to.roc)
customer=read.csv('data/customer.csv',header=TRUE)
head(customer)
str(customer)
head(customer)
Sys.setlocale("LC_ALL","C")
customer_s =scale(customer[,-1])
?scale
round(mean(customer_s[,2]),3)
round(sd(customer_s[,2]),3)
str(customer_s)
set.seed(22)
fit =kmeans(customer_s, centers=4)
barplot(t(fit$centers), beside =TRUE,xlab="cluster", ylab="value")
str(fit)
fit$centers
fit$cluster
plot(customer, col=fit$cluster)
fit$centers
plot(customer, col=fit$cluster)
install.packages("cluster")
install.packages("cluster")
library(cluster)
clusplot(customer_s, fit$cluster, color=TRUE, shade=TRUE)    #4維投影2維
cov_xy = sum((x - mean(x)) * (y - mean(y))) / 2
cov_xy
gdp = read.csv("data/gdp.csv",header=TRUE)
gdp = gdp[1:15,]
gdp$GDP = as.numeric(sub(",", "", gdp$GDP))
gdp$Export = as.numeric(sub(",", "", gdp$Export))
cor(gdp$Export, gdp$GDP)
install.packages("C50")
library(C50)
data(churn)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
ind<-sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
table(sample(x = 1:2,size = 100, replace=T))
set.seed(1)
table(sample(x = 1:2,size = 100, replace=T, prob=c(0.7,0.3)))
install.packages('rpart')
install.packages("rpart")
library('rpart')
churn.rp<-rpart(churn ~ ., data=trainset)     #churn資料的所有類別做分類
churn.rp
summary(churn.rp)
con = rpart.control(cp=0.01)          #rpart.control(事前修剪  minsplit節點幣數)
?rpart.control
churn
str(churn)
churn.rp<-rpart(churn ~ ., data=trainset)     #churn資料的所有類別做分類
churn.rp
summary(churn.rp)
con = rpart.control(cp=0.01)          #rpart.control(事前修剪  minsplit節點幣數)
?rpart.control
churn.rp<-rpart(churn ~., data=trainset,control = con)
str(churn)
str(churn.rp)
str(churn)
data(churn)
str(churn)
str(trainset)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')    #篩選資料
!names(churnTrain) %in% c("state", "area_code", "account_length")
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')    #篩選資料
variable.list
churnTrain=churnTrain[,variable.list]        #充新寫入欄位
churnTrain
churnTrain
variable.list
str(variable.list)
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')    #篩選資料
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')    #篩選資料
variable.list
install.packages("C50")
install.packages("C50")
library(C50)
data(churn)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
type(churnTrain)
a = c(1,2,3,4,5,6,7,8,9)
ind = c(1,0,1,0,1,0,1,0,1)
ind == 1
a[ind == 1]
a[ind == 0]
table(sample(x = 1:2,size = 100, replace=T, prob=c(0.7,0.3)))
ind<-sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
trainset
churn.rp<-rpart(churn ~ ., data=trainset)     #churn資料的所有類別做分類
churn.rp
summary(churn.rp)
str(churn)
str(trainset)
con = rpart.control(cp=0.01)          #rpart.control(事前修剪  minsplit節點幣數)
?rpart.control
churn.rp<-rpart(churn ~., data=trainset,control = con)
churn.rp
summary(churn.rp)
con = rpart.control(cp=0.1)          #rpart.control(事前修剪  minsplit節點臂數)  只長到0.01
?rpart.control
churn.rp<-rpart(churn ~., data=trainset,control = con)   #
summary(churn.rp)
par(mfrow=c(1,1))                                        #par 畫布切割
plot(churn.rp, margin=0.1)
par(mfrow=c(1,1))
plot(churn.rp, margin=0.1)
con = rpart.control(cp=0.01)          #rpart.control(事前修剪  minsplit節點幣數)
?rpart.control
churn.rp<-rpart(churn ~., data=trainset,control = con)
par(mfrow=c(1,1))
plot(churn.rp, margin=0.1)
plot(churn.rp, uniform=TRUE,branch = 0.6, margin=0.1)      #長度相同  branch彎曲
?plot.rpart
text(churn.rp)
text(churn.rp, all=TRUE, use.n=TRUE)
printcp(churn.rp)
plotcp(churn.rp)
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
prune.tree=prune(churn.rp, cp=churn.cp)
churn.cp = churn.rp$cptable[which.min(churn.rp$cptable[,"xerror"]), "CP"]  #0.01
prune.tree=prune(churn.rp, cp=churn.cp)
prune.tree=prune(churn.rp, cp=churn.cp)
plot(prune.tree, margin=0.1)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)
predictions <-predict(prune.tree, testset,type = "class")
table(testset$churn, predictions)
prune.tree
summary(prune.tree)
table(testset$churn, predictions)
predictions
confusionMatrix(table(predictions, testset$churn))
install.packages('caret')
install.packages('caret')
install.packages('e1071')
library('caret')
library('e1071')
confusionMatrix(table(predictions, testset$churn))
install.packages("party")
library('party')
plot(ctree.model, margin=0.1)
ctree.model = ctree(churn ~ . , data = trainset)
plot(ctree.model, margin=0.1)
daycharge.model = ctree(churn ~ total_day_charge + international_plan, data = trainset)
plot(daycharge.model)                #2個參數建模   不用修剪
ctree.predict = predict(ctree.model ,testset)
table(ctree.predict, testset$churn)
confusionMatrix(table(ctree.predict, testset$churn))
plot(daycharge.model)                #y~X   不用修剪
ctree.predict = predict(ctree.model ,testset)
table(ctree.predict, testset$churn)
x= c(3,3,4,3,6,8,8,9)
y= c(22,25,18,20,16,9,12,5)
new_x = data.frame(x=5)
train = data.frame(x=x,y=y)
imTrain = lm(formula = y~x,data=train)
summary(LmTrain)
summary(LmTrain)
plot(y~x,main="醫藥劑量預測痊癒天數",xlab="藥劑量",ylab="感冒痊癒天數",family="STHeiti")
points(x=new_x,y=predicted,col="green",cex=2,pch=16)
abline(reg=imTrain$coefficients,col="red",lwd=1)
points(x=new_x,y=predicted,col="green",cex=2,pch=16)
points(x=new_x, y=predicted, col="green", cex=2, pch=16)
predicted = predict(imTrain,new = new_x)
points(x=new_x, y=predicted, col="green", cex=2, pch=16)
abline(reg=imTrain$coefficients,col="red",lwd=1)
setwd("C:/riii")
library(RJDBC)
install.package("RJDBC")
install.packages("RJDBC")
library(RJDBC)
drv = JDBC("com.mysql.jdbc.Driver","C:\\mysql-connector-java-5.1.42-bin.jar")
conn = dbConnect(drv,
"jdbc:mysql://172.104.90.53:3306/iii",
"iii",
"iii@WSX1qaz"
)
class(a)
dbListTables(conn)
dbReadTable(conn,"airquality")
a= dbGetQuery(conn,"select * from airquality")
class(a)
drv = JDBC("com.mysql.jdbc.Driver","C:\\mysql-connector-java-5.1.42-bin.jar")
conn = dbConnect(drv,
"jdbc:mysql://172.104.90.53:3306/iii",
"iii",
"iii@WSX1qaz"
)
dbListTables(conn)
a= dbGetQuery(conn,"select*from airquality")
class(a)
dbListTables(conn)
dbReadTable(conn,"airquality")
dbListTables(conn)
dbListTables(conn)
df_sensor <- sqldf("SELECT cast(substr(trim(dt),7,1) as int) month
,cast(substr(trim(dt),9,2) as int) day
,avg(temperature) avg_temperature
,avg(humidity) avg_humidity
FROM sensor
group by
cast(substr(trim(dt),7,1) as int)
,cast(substr(trim(dt),9,2) as int)
having cast(substr(trim(dt),7,1) as int) <>0
")
install.packages("sqldf")
install.packages("sqldf")
install.packages("sqldf")
install.packages("sqldf")
install.packages("sqldf")
drv = JDBC("com.mysql.jdbc.Driver","C:\\mysql-connector-java-5.1.42-bin.jar")
conn = dbConnect(drv,
"jdbc:mysql://172.104.90.53:3306/iii",
"iii",
"iii@WSX1qaz"
)
dbListTables(conn)
a= dbGetQuery(conn,"select*from airquality")
sensor <-dbReadTable(conn,"sensor")
sensor <-dbGetQuery(conn,"select*from sensor")
airquality <-dbGetQuery(conn,"select*from airquality")
df_sensor <- sqldf("SELECT cast(substr(trim(dt),7,1) as int) month
,cast(substr(trim(dt),9,2) as int) day
,avg(temperature) avg_temperature
,avg(humidity) avg_humidity
FROM sensor
group by
cast(substr(trim(dt),7,1) as int)
,cast(substr(trim(dt),9,2) as int)
having cast(substr(trim(dt),7,1) as int) <>0
")
df_allitems <- sqldf(" select a.*,b.avg_temperature,b.avg_humidity
from airquality a
left join df_sensor b
on a.Month=b.month and a.Day = b.day
")
lmTrain <- lm(formula = Ozone ~ Solar_R+Wind+avg_temperature+avg_humidity,
data = subset(df_allitems, complete.cases(df_allitems))) #排除null
summary(lmTrain )
install.packages("sqldf")
library(sqldf)
df_sensor <- sqldf("SELECT cast(substr(trim(dt),7,1) as int) month
,cast(substr(trim(dt),9,2) as int) day
,avg(temperature) avg_temperature
,avg(humidity) avg_humidity
FROM sensor
group by
cast(substr(trim(dt),7,1) as int)
,cast(substr(trim(dt),9,2) as int)
having cast(substr(trim(dt),7,1) as int) <>0
")
install.packages("sqldf")
library(sqldf)
install.packages("RSQLite")
install.packages("RSQLite")
df_sensor <- sqldf("SELECT cast(substr(trim(dt),7,1) as int) month
,cast(substr(trim(dt),9,2) as int) day
,avg(temperature) avg_temperature
,avg(humidity) avg_humidity
FROM sensor
group by
cast(substr(trim(dt),7,1) as int)
,cast(substr(trim(dt),9,2) as int)
having cast(substr(trim(dt),7,1) as int) <>0
")
install.packages("sqldf")
library(sqldf)
df_sensor <- sqldf("SELECT cast(substr(trim(dt),7,1) as int) month
,cast(substr(trim(dt),9,2) as int) day
,avg(temperature) avg_temperature
,avg(humidity) avg_humidity
FROM sensor
group by
cast(substr(trim(dt),7,1) as int)
,cast(substr(trim(dt),9,2) as int)
having cast(substr(trim(dt),7,1) as int) <>0
")
df_allitems <- sqldf(" select a.*,b.avg_temperature,b.avg_humidity
from airquality a
left join df_sensor b
on a.Month=b.month and a.Day = b.day
")
lmTrain <- lm(formula = Ozone ~ Solar_R+Wind+avg_temperature+avg_humidity,
data = subset(df_allitems, complete.cases(df_allitems))) #排除null
summary(lmTrain )
predicted <- predict(lmTrain , newdata = New_data)
New_data <- data.frame(Solar_R =200, Wind=12, avg_temperature=32.1, avg_humidity =62.7)
predicted <- predict(lmTrain , newdata = New_data)
predicted/1000
dbDisconnect(conn)
conn
df_sensor <- sqldf("SELECT cast(substr(trim(dt),7,1) as int) month
,cast(substr(trim(dt),9,2) as int) day
,avg(temperature) avg_temperature
,avg(humidity) avg_humidity
FROM sensor
group by
cast(substr(trim(dt),7,1) as int)
,cast(substr(trim(dt),9,2) as int)
having cast(substr(trim(dt),7,1) as int) <>0
")
lmTrain <- lm(formula = Ozone ~ Solar_R+Wind+avg_temperature+avg_humidity,
data = subset(df_allitems, complete.cases(df_allitems))) #排除null
New_data <- data.frame(Solar_R =200, Wind=12, avg_temperature=32.1, avg_humidity =62.7)
predicted <- predict(lmTrain , newdata = New_data)
predicted/1000
head(airquality, 10)
summary(lmTrain )
lmTrain2 <- lm(formula = Ozone ~ Solar_R+Wind+avg_temperature+avg_humidity,
data = subset(df_allitems, complete.cases(df_allitems))) #排除null
lmTrain2 <- lm(formula = Ozone ~ Solar_R+Wind,
data = subset(df_allitems, complete.cases(df_allitems))) #排除null
summary(lmTrain2)
dbDisconnect(conn)
cast(substr(trim(dt),7,1) as int)
?cast
trim(dt)
df_sensor$month
?substr
df_sensor$day
?CART
